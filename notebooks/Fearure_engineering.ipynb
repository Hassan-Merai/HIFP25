{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3560109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed90c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_merged_data():\n",
    "    \"\"\"\n",
    "    Load all merged data from S3.\n",
    "    \"\"\"\n",
    "    merged_dtypes = {\n",
    "    'ClaimID': 'object',\n",
    "    'ClaimStartDt': 'object',\n",
    "    'ClaimEndDt': 'object',\n",
    "    'Provider' : 'object',\n",
    "    'InscClaimAmtReimbursed' : 'float64',\n",
    "    'AttendingPhysician' :'object',\n",
    "    'OperatingPhysician' :'object',\n",
    "    'OtherPhysician' :'object',\n",
    "    'AdmissionDt'  :'object',\n",
    "    'ClmAdmitDiagnosisCode' :'object',\n",
    "    'DeductibleAmtPaid' :'float64',\n",
    "    'IPAnnualReimbursementAmt': 'float64',\n",
    "    'OPAnnualReimbursementAmt': 'float64',\n",
    "    'DischargeDt' :'object',\n",
    "    'ClmAdmitDiagnosisCode': 'object',\n",
    "    'ClmDiagnosisCode_1': 'object',\n",
    "    'ClmDiagnosisCode_2': 'object',\n",
    "    'ClmDiagnosisCode_3': 'object',\n",
    "    'ClmDiagnosisCode_4': 'object',\n",
    "    'ClmDiagnosisCode_5': 'object',\n",
    "    'ClmDiagnosisCode_6': 'object',\n",
    "    'ClmDiagnosisCode_7': 'object',\n",
    "    'ClmDiagnosisCode_8': 'object',\n",
    "    'ClmDiagnosisCode_9': 'object',\n",
    "    'ClmDiagnosisCode_10': 'object', \n",
    "    'DiagnosisGroupCode': 'object',\n",
    "    'IPAnnualDeductibleAmt': 'float64',\n",
    "    'OPAnnualDeductibleAmt': 'float64',\n",
    "    }\n",
    "    #date_columns_in = ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt']\n",
    "    clean_path = \"s3://medicare-fraud-data-25-05-2025/clean/\"\n",
    "    df_train = dd.read_csv(clean_path+\"train_full/*.csv\", dtype=merged_dtypes)\n",
    "    df_test = dd.read_csv(clean_path+\"test_full/*.csv\", dtype=merged_dtypes)\n",
    "    print(\"Data loaded successfully\")\n",
    "    \n",
    "    return (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63a2c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "df_train, df_test = load_merged_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c95062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#def convert_dates(df):\n",
    "#    \"\"\"\n",
    "#    Convert date columns to datetime format.\n",
    "#    \"\"\"\n",
    "#    date_columns_in = ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt']\n",
    "#    for col in date_columns_in:\n",
    "#        df[col] = dd.to_datetime(df[col], errors='coerce')\n",
    "#    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67385bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def revert_dates(df):\n",
    "#    \"\"\"\n",
    "#    Konvertiert Datetime-Spalten zurück in Strings im ISO-Format (YYYY-MM-DD).\n",
    "#    \"\"\"\n",
    "#    date_columns_in = ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt']\n",
    "#    for col in date_columns_in:\n",
    "#        # Prüfen, ob Spalte im DataFrame existiert und vom Datetime-Typ ist\n",
    "#        if col in df.columns:\n",
    "#            df[col] = df[col].asstype('object')  # Konvertiert Datetime zurück in String\n",
    "#    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dc53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train=convert_dates(df_train)\n",
    "#df_test=convert_dates(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed69b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']\n"
     ]
    }
   ],
   "source": [
    "physician_cols = [col for col in df_test.columns if \"Physician\" in col]\n",
    "print(physician_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2bd426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Replacing NANs in all Physician Columns by Zero\n",
    "cols_to_fill = ['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']\n",
    "df_test[cols_to_fill] = df_test[cols_to_fill].fillna(0)\n",
    "df_train[cols_to_fill] = df_train[cols_to_fill].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d715ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sum of the Beneficiary Age for every Provider\n",
    "bene_age_sum_per_prv = df_test.groupby(\"Provider\")[\"Bene_Age\"].sum().reset_index()\n",
    "bene_age_sum_per_prv = bene_age_sum_per_prv.rename(columns={\"Bene_Age\": \"Bene_Age_Sum\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858f4ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>TotalClaims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: operation, 11 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Provider TotalClaims\n",
       "npartitions=1                     \n",
       "                string       int64\n",
       "                   ...         ...\n",
       "Dask Name: operation, 11 expressions\n",
       "Expr=ColumnsSetter(frame=ResetIndex(frame=Count(frame=Assign(frame=ReadCSV(69e46bf))[['ClaimID', 'Provider']], observed=False, _slice='ClaimID')), columns=['Provider', 'TotalClaims'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Number of Total Claims per Provider. The original Idea was to identify the Total Number of false Claims by a Provider. For that he subtract the number of fradulent claims from the number of total claims\n",
    "total_claims_per_prv = df_test.groupby(\"Provider\")[\"ClaimID\"].count().reset_index()\n",
    "total_claims_per_prv.columns = [\"Provider\", \"TotalClaims\"]\n",
    "total_claims_per_prv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e06cb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_claims_per_provider_physicians(df):\n",
    "    \"\"\"\n",
    "    Compute total claims per provider for each physician type, and return one merged Dask DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count total claims per provider-physician type\n",
    "    att = df.groupby([\"Provider\", \"AttendingPhysician\"])[\"ClaimID\"].count().reset_index()\n",
    "    att = att.rename(columns={\"ClaimID\": \"AttendingPhysician_TotalClaims\"})\n",
    "\n",
    "    #op = df.groupby([\"Provider\", \"OperatingPhysician\"])[\"ClaimID\"].count().reset_index()\n",
    "    #op = op.rename(columns={\"ClaimID\": \"OperatingPhysician_TotalClaims\"})\n",
    "#\n",
    "    #ot = df.groupby([\"Provider\", \"OtherPhysician\"])[\"ClaimID\"].count().reset_index()\n",
    "    #ot = ot.rename(columns={\"ClaimID\": \"OtherPhysician_TotalClaims\"})\n",
    "#\n",
    "    ## Now reduce these to provider-level totals by summing claims per provider\n",
    "    att_sum = att.groupby(\"Provider\")[\"AttendingPhysician_TotalClaims\"].sum().reset_index()\n",
    "    #op_sum = op.groupby(\"Provider\")[\"OperatingPhysician_TotalClaims\"].sum().reset_index()\n",
    "    #ot_sum = ot.groupby(\"Provider\")[\"OtherPhysician_TotalClaims\"].sum().reset_index()\n",
    "\n",
    "    # Merge safely\n",
    "    #merged = att_sum.merge(op_sum, on=\"Provider\", how=\"outer\")\n",
    "    #merged = merged.merge(ot_sum, on=\"Provider\", how=\"outer\")\n",
    "\n",
    "    return att_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f5122e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=total_claims_per_provider_physicians(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bacc0afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>AttendingPhysician_TotalClaims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51002</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51006</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51009</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51010</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51018</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  AttendingPhysician_TotalClaims\n",
       "0  PRV51002                             205\n",
       "1  PRV51006                             102\n",
       "2  PRV51009                              39\n",
       "3  PRV51010                              38\n",
       "4  PRV51018                             190"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce976b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Prv_Physician_Count\n",
    "def count_unique_physicians(df, physician_col):\n",
    "    \"\"\"\n",
    "    Count unique physicians for each provider.\n",
    "    If multiple columns are provided, all unique physician IDs across them are counted.\n",
    "    Works with Dask DataFrames.\n",
    "    \"\"\"\n",
    "    if isinstance(physician_col, list):\n",
    "        # Combine provider with all physician columns, then reshape and deduplicate\n",
    "        dfs = []\n",
    "        for col in physician_col:\n",
    "            temp = df[[\"Provider\", col]].rename(columns={col: \"Physician\"}).dropna()\n",
    "            dfs.append(temp)\n",
    "        \n",
    "        combined = dd.concat(dfs)\n",
    "        unique_counts = (\n",
    "            combined.dropna()\n",
    "            .drop_duplicates()\n",
    "            .groupby(\"Provider\")[\"Physician\"]\n",
    "            .nunique()\n",
    "            .reset_index()\n",
    "        )\n",
    "        unique_counts = unique_counts.rename(columns={\"Physician\": \"Prv_Physician_Count\"})\n",
    "\n",
    "    else:\n",
    "        unique_counts = (\n",
    "            df.groupby(\"Provider\")[physician_col]\n",
    "            .nunique()\n",
    "            .reset_index()\n",
    "            .rename(columns={physician_col: f\"{physician_col}_Count\"})\n",
    "        )\n",
    "\n",
    "    return unique_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483409eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_Attphysician_count = count_unique_physicians(df_test, \"AttendingPhysician\")\n",
    "pr_OPphysician_count = count_unique_physicians(df_test, \"OperatingPhysician\")\n",
    "pr_Otphysician_count = count_unique_physicians(df_test, \"OtherPhysician\")\n",
    "pr_allphysician_count = count_unique_physicians(df_test, [\"AttendingPhysician\", \"OperatingPhysician\", \"OtherPhysician\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c716667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>Prv_Physician_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: operation, 23 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Provider Prv_Physician_Count\n",
       "npartitions=3                             \n",
       "                string               int64\n",
       "                   ...                 ...\n",
       "                   ...                 ...\n",
       "                   ...                 ...\n",
       "Dask Name: operation, 23 expressions\n",
       "Expr=RenameFrame(frame=ResetIndex(frame=NUnique(frame=(DropDuplicates(frame=DropnaFrame(frame=Concat(frames=[DropnaFrame(frame=RenameFrame(frame=Assign(frame=ReadCSV(69e46bf))[['Provider', 'AttendingPhysician']], columns={'AttendingPhysician': 'Physician'})), DropnaFrame(frame=RenameFrame(frame=Assign(frame=ReadCSV(69e46bf))[['Provider', 'OperatingPhysician']], columns={'OperatingPhysician': 'Physician'})), DropnaFrame(frame=RenameFrame(frame=Assign(frame=ReadCSV(69e46bf))[['Provider', 'OtherPhysician']], columns={'OtherPhysician': 'Physician'}))], ))))[['Provider', 'Physician']], observed=False, _slice='Physician', split_every=None, split_out=True)), columns={'Physician': 'Prv_Physician_Count'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_allphysician_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "346f3ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>Provider_Insurance_Claim_Reimbursement_Amt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: operation, 11 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Provider Provider_Insurance_Claim_Reimbursement_Amt\n",
       "npartitions=1                                                    \n",
       "                string                                    float64\n",
       "                   ...                                        ...\n",
       "Dask Name: operation, 11 expressions\n",
       "Expr=RenameFrame(frame=ResetIndex(frame=Sum(frame=Assign(frame=ReadCSV(69e46bf))[['Provider', 'InscClaimAmtReimbursed']], observed=False, chunk_kwargs={'numeric_only': False}, aggregate_kwargs={'numeric_only': False}, _slice='InscClaimAmtReimbursed')), columns={'InscClaimAmtReimbursed': 'Provider_Insurance_Claim_Reimbursement_Amt'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Provider_Insurance_Clam_Reimbursement_Amt\n",
    "def calculate_provider_insurance_reimbursement(df):\n",
    "    \"\"\"\n",
    "    Calculate the total insurance reimbursement amount per provider.\n",
    "    \"\"\"\n",
    "    return df.groupby(\"Provider\")[\"InscClaimAmtReimbursed\"].sum().reset_index().rename(\n",
    "        columns={\"InscClaimAmtReimbursed\": \"Provider_Insurance_Claim_Reimbursement_Amt\"}\n",
    "    )\n",
    "provider_insurance_reimbursement = calculate_provider_insurance_reimbursement(df_test)\n",
    "provider_insurance_reimbursement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f1b3d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>Provider_Total_Patients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: operation, 11 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Provider Provider_Total_Patients\n",
       "npartitions=1                                 \n",
       "                string                   int64\n",
       "                   ...                     ...\n",
       "Dask Name: operation, 11 expressions\n",
       "Expr=RenameFrame(frame=ResetIndex(frame=NUnique(frame=Assign(frame=ReadCSV(69e46bf))[['BeneID', 'Provider']], observed=False, _slice='BeneID', split_every=None, split_out=True)), columns={'BeneID': 'Provider_Total_Patients'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11. Provider_Total_Patients\n",
    "def calculate_provider_total_patients(df):\n",
    "    \"\"\"\n",
    "    Calculate the total number of unique patients per provider.\n",
    "    \"\"\"\n",
    "    return df.groupby(\"Provider\")[\"BeneID\"].nunique().reset_index().rename(\n",
    "        columns={\"BeneID\": \"Provider_Total_Patients\"}\n",
    "    )\n",
    "provider_total_patients = calculate_provider_total_patients(df_test)\n",
    "provider_total_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb50a90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>Provider_Total_ChronicCond_Alzheimer_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_Heartfailure_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_KidneyDisease_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_Cancer_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_ObstrPulmonary_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_Depression_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_Diabetes_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_IschemicHeart_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_Osteoporasis_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_rheumatoidarthritis_Patients</th>\n",
       "      <th>Provider_Total_ChronicCond_stroke_Patients</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: operation, 11 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Provider Provider_Total_ChronicCond_Alzheimer_Patients Provider_Total_ChronicCond_Heartfailure_Patients Provider_Total_ChronicCond_KidneyDisease_Patients Provider_Total_ChronicCond_Cancer_Patients Provider_Total_ChronicCond_ObstrPulmonary_Patients Provider_Total_ChronicCond_Depression_Patients Provider_Total_ChronicCond_Diabetes_Patients Provider_Total_ChronicCond_IschemicHeart_Patients Provider_Total_ChronicCond_Osteoporasis_Patients Provider_Total_ChronicCond_rheumatoidarthritis_Patients Provider_Total_ChronicCond_stroke_Patients\n",
       "npartitions=1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "                string                                         int64                                            int64                                             int64                                      int64                                              int64                                          int64                                        int64                                             int64                                            int64                                                   int64                                      int64\n",
       "                   ...                                           ...                                              ...                                               ...                                        ...                                                ...                                            ...                                          ...                                               ...                                              ...                                                     ...                                        ...\n",
       "Dask Name: operation, 11 expressions\n",
       "Expr=RenameFrame(frame=ResetIndex(frame=Sum(frame=Assign(frame=ReadCSV(69e46bf))[['Provider', 'ChronicCond_Alzheimer', 'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease', 'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression', 'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke']], observed=False, chunk_kwargs={'numeric_only': False}, aggregate_kwargs={'numeric_only': False}, _slice=['ChronicCond_Alzheimer', 'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease', 'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression', 'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke'])), columns={'ChronicCond_Alzheimer': 'Provider_Total_ChronicCond_Alzheimer_Patients', 'ChronicCond_Heartfailure': 'Provider_Total_ChronicCond_Heartfailure_Patients', 'ChronicCond_KidneyDisease': 'Provider_Total_ChronicCond_KidneyDisease_Patients', 'ChronicCond_Cancer': 'Provider_Total_ChronicCond_Cancer_Patients', 'ChronicCond_ObstrPulmonary': 'Provider_Total_ChronicCond_ObstrPulmonary_Patients', 'ChronicCond_Depression': 'Provider_Total_ChronicCond_Depression_Patients', 'ChronicCond_Diabetes': 'Provider_Total_ChronicCond_Diabetes_Patients', 'ChronicCond_IschemicHeart': 'Provider_Total_ChronicCond_IschemicHeart_Patients', 'ChronicCond_Osteoporasis': 'Provider_Total_ChronicCond_Osteoporasis_Patients', 'ChronicCond_rheumatoidarthritis': 'Provider_Total_ChronicCond_rheumatoidarthritis_Patients', 'ChronicCond_stroke': 'Provider_Total_ChronicCond_stroke_Patients'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12. Provider_Total_Chronic_Alzheimer Patients\n",
    "\n",
    "def calculate_provider_total_chronic_patients(df, chronic_cols):\n",
    "    \"\"\"\n",
    "    Calculates the total number of patients per provider for each chronic condition.\n",
    "\n",
    "    Parameters:\n",
    "        df (Dask or Pandas DataFrame): Input beneficiary DataFrame\n",
    "        chronic_cols (list of str): List of chronic condition columns (values should be 0 or 1)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with one row per provider and total counts of each chronic condition.\n",
    "    \"\"\"\n",
    "    # Check if all columns exist\n",
    "    missing = [col for col in chronic_cols if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"The following columns are missing: {missing}\")\n",
    "    \n",
    "    # Group and sum per provider\n",
    "    agg_df = df.groupby(\"Provider\")[chronic_cols].sum().reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    agg_df = agg_df.rename(columns={col: f\"Provider_Total_{col}_Patients\" for col in chronic_cols})\n",
    "\n",
    "    return agg_df\n",
    "chronic_cols = [\n",
    "    \"ChronicCond_Alzheimer\",\n",
    "    \"ChronicCond_Heartfailure\",\n",
    "    \"ChronicCond_KidneyDisease\",\n",
    "    \"ChronicCond_Cancer\",\n",
    "    \"ChronicCond_ObstrPulmonary\",\n",
    "    \"ChronicCond_Depression\",\n",
    "    \"ChronicCond_Diabetes\",\n",
    "    \"ChronicCond_IschemicHeart\",\n",
    "    \"ChronicCond_Osteoporasis\",\n",
    "    \"ChronicCond_rheumatoidarthritis\",\n",
    "    \"ChronicCond_stroke\"\n",
    "]\n",
    "\n",
    "provider_total_chronic_patients = calculate_provider_total_chronic_patients(df_test, chronic_cols)\n",
    "provider_total_chronic_patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e33d50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>ClmAdmitDiagnosisCode_Count</th>\n",
       "      <th>ClmDiagnosisCode_1_Count</th>\n",
       "      <th>ClmDiagnosisCode_2_Count</th>\n",
       "      <th>ClmDiagnosisCode_3_Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: merge, 26 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Provider ClmAdmitDiagnosisCode_Count ClmDiagnosisCode_1_Count ClmDiagnosisCode_2_Count ClmDiagnosisCode_3_Count\n",
       "npartitions=1                                                                                                                \n",
       "                string                       int64                    int64                    int64                    int64\n",
       "                   ...                         ...                      ...                      ...                      ...\n",
       "Dask Name: merge, 26 expressions\n",
       "Expr=Merge(ddf408a)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14. count of diagnosis for every Provider\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def count_diagnosis_per_provider(df, diagnosis_cols):\n",
    "    \"\"\"\n",
    "    Count non-null occurrences of each diagnosis code per provider.\n",
    "    \n",
    "    Parameters:\n",
    "        df (Dask DataFrame): Input DataFrame containing diagnosis codes\n",
    "        diagnosis_cols (list of str): List of diagnosis code columns\n",
    "    \n",
    "    Returns:\n",
    "        Dask DataFrame with counts of each diagnosis column per provider\n",
    "    \"\"\"\n",
    "    # Start with the first column's counts\n",
    "    result = df.groupby(\"Provider\")[diagnosis_cols[0]].count().reset_index().rename(\n",
    "        columns={diagnosis_cols[0]: f\"{diagnosis_cols[0]}_Count\"}\n",
    "    )\n",
    "    \n",
    "    # Iterate through remaining diagnosis columns and join counts\n",
    "    for col in diagnosis_cols[1:]:\n",
    "        temp = df.groupby(\"Provider\")[col].count().reset_index().rename(\n",
    "            columns={col: f\"{col}_Count\"}\n",
    "        )\n",
    "        result = result.merge(temp, on=\"Provider\", how=\"outer\")\n",
    "\n",
    "    return result\n",
    "diagnosis_cols = [\n",
    "    \"ClmAdmitDiagnosisCode\",\n",
    "    \"ClmDiagnosisCode_1\",\n",
    "    \"ClmDiagnosisCode_2\",\n",
    "    \"ClmDiagnosisCode_3\"\n",
    "]\n",
    "diagnosis_counts_per_provider = count_diagnosis_per_provider(df_test, diagnosis_cols)\n",
    "diagnosis_counts_per_provider\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f8ced",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TotalClaims'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TotalClaims'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 16. Real Average Claims per Provider we have to run this after merging the dataframes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal_avg_claims_per_provider\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotalClaims\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotalClaims\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_collection.py:413\u001b[0m, in \u001b[0;36mFrameBase.__getitem__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    412\u001b[0m     other \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_collection.py:4794\u001b[0m, in \u001b[0;36mnew_collection\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m   4792\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_collection\u001b[39m(expr):\n\u001b[1;32m   4793\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create new collection from an expr\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4794\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n\u001b[1;32m   4795\u001b[0m     expr\u001b[38;5;241m.\u001b[39m_name  \u001b[38;5;66;03m# Ensure backend is imported\u001b[39;00m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_collection_type(meta)(expr)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/functools.py:993\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    991\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 993\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_expr.py:2050\u001b[0m, in \u001b[0;36mProjection._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dataframe_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39m_meta):\n\u001b[0;32m-> 2050\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n\u001b[1;32m   2051\u001b[0m     \u001b[38;5;66;03m# if we are not a DataFrame and have a scalar, we reduce to a scalar\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mslice\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2053\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2054\u001b[0m     ):\n",
      "File \u001b[0;32m/usr/lib64/python3.9/functools.py:993\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    991\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 993\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_expr.py:496\u001b[0m, in \u001b[0;36mBlockwise._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    495\u001b[0m     args \u001b[38;5;241m=\u001b[39m [op\u001b[38;5;241m.\u001b[39m_meta \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, Expr) \u001b[38;5;28;01melse\u001b[39;00m op \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args]\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TotalClaims'"
     ]
    }
   ],
   "source": [
    "# 16. Real Average Claims per Provider we have to run this after merging the dataframes\n",
    "#df_train['real_avg_claims_per_provider'] = df_train['TotalClaims'] - df_train['TotalClaims'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0998430d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Provider_Insurance_Claim_Reimbursement_Amt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Provider_Insurance_Claim_Reimbursement_Amt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 16. Average of Claimcost for every Provider\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal_avg_claim_cost_per_provider\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProvider_Insurance_Claim_Reimbursement_Amt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProvider_Insurance_Claim_Reimbursement_Amt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()  \n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_collection.py:413\u001b[0m, in \u001b[0;36mFrameBase.__getitem__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    412\u001b[0m     other \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_collection.py:4794\u001b[0m, in \u001b[0;36mnew_collection\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m   4792\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_collection\u001b[39m(expr):\n\u001b[1;32m   4793\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create new collection from an expr\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4794\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n\u001b[1;32m   4795\u001b[0m     expr\u001b[38;5;241m.\u001b[39m_name  \u001b[38;5;66;03m# Ensure backend is imported\u001b[39;00m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_collection_type(meta)(expr)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/functools.py:993\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    991\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 993\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_expr.py:2050\u001b[0m, in \u001b[0;36mProjection._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dataframe_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39m_meta):\n\u001b[0;32m-> 2050\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n\u001b[1;32m   2051\u001b[0m     \u001b[38;5;66;03m# if we are not a DataFrame and have a scalar, we reduce to a scalar\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mslice\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m   2053\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2054\u001b[0m     ):\n",
      "File \u001b[0;32m/usr/lib64/python3.9/functools.py:993\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    991\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 993\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_expr.py:496\u001b[0m, in \u001b[0;36mBlockwise._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    495\u001b[0m     args \u001b[38;5;241m=\u001b[39m [op\u001b[38;5;241m.\u001b[39m_meta \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, Expr) \u001b[38;5;28;01melse\u001b[39;00m op \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args]\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Provider_Insurance_Claim_Reimbursement_Amt'"
     ]
    }
   ],
   "source": [
    "# 16. Average of Claimcost for every Provider\n",
    "df_train['real_avg_claim_cost_per_provider'] = df_train['Provider_Insurance_Claim_Reimbursement_Amt'] - df_train['Provider_Insurance_Claim_Reimbursement_Amt'].mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Median of the Claimscost for every Provider\n",
    "df_train['real_median_claim_cost_per_provider'] = df_train['Provider_Insurance_Claim_Reimbursement_Amt'] - df_train['Provider_Insurance_Claim_Reimbursement_Amt'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c88d126d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>ClmAdmitDiagnosisCode_Most_Frequent</th>\n",
       "      <th>ClmDiagnosisCode_1_Most_Frequent</th>\n",
       "      <th>ClmDiagnosisCode_2_Most_Frequent</th>\n",
       "      <th>ClmDiagnosisCode_3_Most_Frequent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: merge, 38 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Provider ClmAdmitDiagnosisCode_Most_Frequent ClmDiagnosisCode_1_Most_Frequent ClmDiagnosisCode_2_Most_Frequent ClmDiagnosisCode_3_Most_Frequent\n",
       "npartitions=1                                                                                                                                                \n",
       "                string                              string                           string                           string                           string\n",
       "                   ...                                 ...                              ...                              ...                              ...\n",
       "Dask Name: merge, 38 expressions\n",
       "Expr=Merge(6eaf3a6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 18. Most frequent Claimcodes for every Provider\n",
    "from functools import reduce\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def most_frequent_claim_codes(df, claim_code_cols):\n",
    "    \"\"\"\n",
    "    Find the most frequent claim code for each provider across multiple columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (Dask DataFrame): Input DataFrame containing claim codes\n",
    "        claim_code_cols (list of str): List of claim code column names\n",
    "    \n",
    "    Returns:\n",
    "        Dask DataFrame: Each row contains Provider and the most frequent code per claim column\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for col in claim_code_cols:\n",
    "        # Count frequencies per Provider per code\n",
    "        code_counts = (\n",
    "            df.groupby([\"Provider\", col])\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"Count\"})\n",
    "        )\n",
    "\n",
    "        # Sort within each partition, then drop duplicates to get most frequent\n",
    "        most_frequent = (\n",
    "            code_counts.map_partitions(lambda pdf: pdf.sort_values(\"Count\", ascending=False))\n",
    "            .drop_duplicates(subset=\"Provider\")\n",
    "            .rename(columns={col: f\"{col}_Most_Frequent\"})\n",
    "            .drop(columns=[\"Count\"])\n",
    "        )\n",
    "\n",
    "        results.append(most_frequent)\n",
    "\n",
    "    # Merge all the most frequent codes per column\n",
    "    final_result = reduce(lambda left, right: left.merge(right, on=\"Provider\", how=\"outer\"), results)\n",
    "\n",
    "    return final_result\n",
    "\n",
    "claim_code_cols = [\n",
    "    \"ClmAdmitDiagnosisCode\",\n",
    "    \"ClmDiagnosisCode_1\",\n",
    "    \"ClmDiagnosisCode_2\",\n",
    "    \"ClmDiagnosisCode_3\",\n",
    "    \n",
    "]\n",
    "most_frequent_codes = most_frequent_claim_codes(df_test, claim_code_cols)\n",
    "most_frequent_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b565d8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>AttendingPhysician_Most_Frequent</th>\n",
       "      <th>OperatingPhysician_Most_Frequent</th>\n",
       "      <th>OtherPhysician_Most_Frequent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: merge, 30 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Provider AttendingPhysician_Most_Frequent OperatingPhysician_Most_Frequent OtherPhysician_Most_Frequent\n",
       "npartitions=1                                                                                                        \n",
       "                string                           string                           string                       string\n",
       "                   ...                              ...                              ...                          ...\n",
       "Dask Name: merge, 30 expressions\n",
       "Expr=Merge(d0f4080)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def most_frequent_physicians(df, physician_cols):\n",
    "    \"\"\"\n",
    "    Find the most frequent physician for each provider across multiple physician columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (Dask DataFrame): Input DataFrame containing provider and physician columns\n",
    "        physician_cols (list of str): List of physician column names\n",
    "    \n",
    "    Returns:\n",
    "        Dask DataFrame: Each row contains Provider and the most frequent physician per column\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for col in physician_cols:\n",
    "        # Count frequencies per Provider per Physician\n",
    "        physician_counts = (\n",
    "            df.groupby([\"Provider\", col])\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"Count\"})\n",
    "        )\n",
    "\n",
    "        # Sort by frequency, then get most frequent physician per provider\n",
    "        most_frequent = (\n",
    "            physician_counts.map_partitions(lambda pdf: pdf.sort_values(\"Count\", ascending=False))\n",
    "            .drop_duplicates(subset=\"Provider\")\n",
    "            .rename(columns={col: f\"{col}_Most_Frequent\"})\n",
    "            .drop(columns=[\"Count\"])\n",
    "        )\n",
    "\n",
    "        results.append(most_frequent)\n",
    "\n",
    "    # Merge all the most frequent physician columns on Provider\n",
    "    final_df = reduce(lambda left, right: left.merge(right, on=\"Provider\", how=\"outer\"), results)\n",
    "\n",
    "    return final_df\n",
    "physician_cols = [\n",
    "    \"AttendingPhysician\",\n",
    "    \"OperatingPhysician\",\n",
    "    \"OtherPhysician\"\n",
    "]\n",
    "most_frequent_physicians_df = most_frequent_physicians(df_test, physician_cols)\n",
    "most_frequent_physicians_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8be32c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Real Average Claims per Provider\n",
    "def calculate_bene_amount(df):\n",
    "    \"\"\"\n",
    "    Return a Dask DataFrame with BeneID, AllocatedAmount (as-is), and summed Deductible & Reimbursed amounts.\n",
    "\n",
    "    Parameters:\n",
    "        df (Dask DataFrame): Input with reimbursement and deductible fields\n",
    "\n",
    "    Returns:\n",
    "        Dask DataFrame with columns: BeneID, AllocatedAmount, DeductibleAmtPaid (sum), InscClaimAmtReimbursed (sum)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Calculate AllocatedAmount (not to be summed)\n",
    "    df[\"AllocatedAmount\"] = df[\"IPAnnualReimbursementAmt\"] + df[\"OPAnnualReimbursementAmt\"]\n",
    "\n",
    "    # Get first AllocatedAmount per BeneID (assuming same for all rows of that BeneID)\n",
    "    allocated = df[[\"BeneID\", \"AllocatedAmount\"]].drop_duplicates(subset=\"BeneID\")\n",
    "\n",
    "    # Sum the other columns per BeneID\n",
    "    summed = df.groupby(\"BeneID\")[[\"DeductibleAmtPaid\", \"InscClaimAmtReimbursed\"]].sum().reset_index()\n",
    "\n",
    "    # Merge\n",
    "    result = allocated.merge(summed, on=\"BeneID\", how=\"left\")\n",
    "\n",
    "    return result\n",
    "\n",
    "bene_amount_df = calculate_remaining_amount(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36ca7e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeneID</th>\n",
       "      <th>AllocatedAmount</th>\n",
       "      <th>DeductibleAmtPaid</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BENE100001</td>\n",
       "      <td>2530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENE100002</td>\n",
       "      <td>14010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENE100004</td>\n",
       "      <td>16150.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENE100010</td>\n",
       "      <td>14450.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENE100012</td>\n",
       "      <td>5870.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>5070.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BeneID  AllocatedAmount  DeductibleAmtPaid  InscClaimAmtReimbursed\n",
       "0  BENE100001           2530.0                0.0                  1100.0\n",
       "1  BENE100002          14010.0                0.0                    60.0\n",
       "2  BENE100004          16150.0             1268.0                 12500.0\n",
       "3  BENE100010          14450.0               80.0                   830.0\n",
       "4  BENE100012           5870.0             1068.0                  5070.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bene_amount_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d610747",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BeneID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23422/4148073912.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m remaining_avg_prv_df= dd.merge(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BeneID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Provider\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbene_amount_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BeneID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_collection.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, suffixes, indicator, shuffle_method, npartitions, broadcast)\u001b[0m\n\u001b[1;32m   5696\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mis_dataframe_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5698\u001b[0m         \u001b[0mwarn_dtype_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5700\u001b[0;31m     return new_collection(\n\u001b[0m\u001b[1;32m   5701\u001b[0m         Merge(\n\u001b[1;32m   5702\u001b[0m             \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5703\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_collection.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m   4792\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnew_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4793\u001b[0m     \u001b[0;34m\"\"\"Create new collection from an expr\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4794\u001b[0;31m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4795\u001b[0m     \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m  \u001b[0;31m# Ensure backend is imported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_collection_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.9/functools.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    997\u001b[0m                         msg = (\n\u001b[1;32m    998\u001b[0m                             \u001b[0;34mf\"The '__dict__' attribute on {type(instance).__name__!r} instance \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m                             \u001b[0;34mf\"does not support item assignment for caching {self.attrname!r} property.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                         )\n\u001b[0;32m-> 1001\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/dask_expr/_merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_nonempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"how\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"leftsemi\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"how\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HIFP25/.venv/lib64/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BeneID'"
     ]
    }
   ],
   "source": [
    "remaining_avg_prv_df= dd.merge(\n",
    "    df_test[[\"BeneID\", \"Provider\"]],\n",
    "    bene_amount_df,\n",
    "    on=\"BeneID\",\n",
    "    how=\"left\"\n",
    ").groupby(\"Provider\")[\"AllocatedAmount\", 'DeductibleAmtPaid', \"InscClaimAmtReimbursed\"].mean().reset_index()\n",
    "remaining_avg_prv_df = remaining_avg_prv_df.rename(\n",
    "    columns={\"AllocatedAmount\": \"Avg_alocated_Amount_Per_Provider\", 'DeductibleAmtPaid': \"Avg_Deductible_Amt_Paid_Per_Provider\", \"InscClaimAmtReimbursed\": \"Avg_InscClaimAmtReimbursed_Per_Provider\" }\n",
    ")\n",
    "remaining_avg_prv_df.head(5)\n",
    "remaining_avg_prv_df['per_utils_remaining_amount'] = (remaining_avg_prv_df[\"Avg_InscClaimAmtReimbursed_Per_Provider\"] - remaining_avg_prv_df[\"Avg_Deductible_Amt_Paid_Per_Provider\"]) /(remaining_avg_prv_df[\"Avg_alocated_Amount_Per_Provider\"] - remaining_avg_prv_df[\"Avg_Deductible_Amt_Paid_Per_Provider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8bedfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>Avg_alocated_Amount_Per_Provider</th>\n",
       "      <th>Avg_Deductible_Amt_Paid_Per_Provider</th>\n",
       "      <th>Avg_InscClaimAmtReimbursed_Per_Provider</th>\n",
       "      <th>per_utils_remaining_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51002</td>\n",
       "      <td>7526.000000</td>\n",
       "      <td>72.409756</td>\n",
       "      <td>1322.585366</td>\n",
       "      <td>0.167728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51006</td>\n",
       "      <td>6169.215686</td>\n",
       "      <td>75.156863</td>\n",
       "      <td>1617.254902</td>\n",
       "      <td>0.253049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51009</td>\n",
       "      <td>5445.128205</td>\n",
       "      <td>121.384615</td>\n",
       "      <td>1767.435897</td>\n",
       "      <td>0.309191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51010</td>\n",
       "      <td>7044.210526</td>\n",
       "      <td>449.684211</td>\n",
       "      <td>4747.105263</td>\n",
       "      <td>0.651665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51018</td>\n",
       "      <td>7551.894737</td>\n",
       "      <td>53.968421</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>0.170451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  Avg_alocated_Amount_Per_Provider  \\\n",
       "0  PRV51002                       7526.000000   \n",
       "1  PRV51006                       6169.215686   \n",
       "2  PRV51009                       5445.128205   \n",
       "3  PRV51010                       7044.210526   \n",
       "4  PRV51018                       7551.894737   \n",
       "\n",
       "   Avg_Deductible_Amt_Paid_Per_Provider  \\\n",
       "0                             72.409756   \n",
       "1                             75.156863   \n",
       "2                            121.384615   \n",
       "3                            449.684211   \n",
       "4                             53.968421   \n",
       "\n",
       "   Avg_InscClaimAmtReimbursed_Per_Provider  per_utils_remaining_amount  \n",
       "0                              1322.585366                    0.167728  \n",
       "1                              1617.254902                    0.253049  \n",
       "2                              1767.435897                    0.309191  \n",
       "3                              4747.105263                    0.651665  \n",
       "4                              1332.000000                    0.170451  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_avg_prv_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
