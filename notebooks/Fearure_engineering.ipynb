{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3560109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed90c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the function to load merged data\n",
    "def load_merged_data():\n",
    "    \"\"\"\n",
    "    Load all merged data from S3.\n",
    "    \"\"\"\n",
    "    merged_dtypes = {\n",
    "    'ClaimID': 'object',\n",
    "    'ClaimStartDt': 'object',\n",
    "    'ClaimEndDt': 'object',\n",
    "    'Provider' : 'object',\n",
    "    'InscClaimAmtReimbursed' : 'float64',\n",
    "    'AttendingPhysician' :'object',\n",
    "    'OperatingPhysician' :'object',\n",
    "    'OtherPhysician' :'object',\n",
    "    'AdmissionDt'  :'object',\n",
    "    'ClmAdmitDiagnosisCode' :'object',\n",
    "    'DeductibleAmtPaid' :'float64',\n",
    "    'IPAnnualReimbursementAmt': 'float64',\n",
    "    'OPAnnualReimbursementAmt': 'float64',\n",
    "    'DischargeDt' :'object',\n",
    "    'ClmAdmitDiagnosisCode': 'object',\n",
    "    'ClmDiagnosisCode_1': 'object',\n",
    "    'ClmDiagnosisCode_2': 'object',\n",
    "    'ClmDiagnosisCode_3': 'object',\n",
    "    'ClmDiagnosisCode_4': 'object',\n",
    "    'ClmDiagnosisCode_5': 'object',\n",
    "    'ClmDiagnosisCode_6': 'object',\n",
    "    'ClmDiagnosisCode_7': 'object',\n",
    "    'ClmDiagnosisCode_8': 'object',\n",
    "    'ClmDiagnosisCode_9': 'object',\n",
    "    'ClmDiagnosisCode_10': 'object', \n",
    "    'DiagnosisGroupCode': 'object',\n",
    "    'IPAnnualDeductibleAmt': 'float64',\n",
    "    'OPAnnualDeductibleAmt': 'float64',\n",
    "    }\n",
    "    #date_columns_in = ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt']\n",
    "    clean_path = \"s3://medicare-fraud-data-25-05-2025/clean/\"\n",
    "    df_train = dd.read_csv(clean_path+\"train_full/*.csv\", dtype=merged_dtypes)\n",
    "    df_test = dd.read_csv(clean_path+\"test_full/*.csv\", dtype=merged_dtypes)\n",
    "    print(\"Data loaded successfully\")\n",
    "    \n",
    "    return (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63a2c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# 3. Call the function to load data\n",
    "df_train, df_test = load_merged_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert date columns to datetime format\n",
    "#def convert_dates(df):\n",
    "#    \"\"\"\n",
    "#    Convert date columns to datetime format.\n",
    "#    \"\"\"\n",
    "#    date_columns_in = ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt']\n",
    "#    for col in date_columns_in:\n",
    "#        df[col] = dd.to_datetime(df[col], errors='coerce')\n",
    "#    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67385bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Uncomment the following lines if you want to revert dates back to strings\n",
    "#def revert_dates(df):\n",
    "#    \"\"\"\n",
    "#    Konvertiert Datetime-Spalten zurück in Strings im ISO-Format (YYYY-MM-DD).\n",
    "#    \"\"\"\n",
    "#    date_columns_in = ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt']\n",
    "#    for col in date_columns_in:\n",
    "#        # Prüfen, ob Spalte im DataFrame existiert und vom Datetime-Typ ist\n",
    "#        if col in df.columns:\n",
    "#            df[col] = df[col].asstype('object')  # Konvertiert Datetime zurück in String\n",
    "#    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed69b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to hold physician columns\n",
    "physician_cols_test = [col for col in df_test.columns if \"Physician\" in col]\n",
    "physician_cols_train = [col for col in df_train.columns if \"Physician\" in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1446704",
   "metadata": {},
   "source": [
    "Starting from here with the new Features V2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2bd426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Replacing NANs in all Physician Columns by Zero\n",
    "cols_to_fill = ['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']\n",
    "df_test[cols_to_fill] = df_test[cols_to_fill].fillna(0)\n",
    "df_train[cols_to_fill] = df_train[cols_to_fill].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d715ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sum of the Beneficiary Age for every Provider\n",
    "prv_bene_age_sum_test = df_test.groupby(\"Provider\")[\"Bene_Age\"].sum().reset_index()\n",
    "prv_bene_age_sum_test = prv_bene_age_sum_test.rename(columns={\"Bene_Age\": \"Bene_Age_Sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37517ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_bene_age_sum_train = df_train.groupby(\"Provider\")[\"Bene_Age\"].sum().reset_index()\n",
    "prv_bene_age_sum_train = prv_bene_age_sum_train.rename(columns={\"Bene_Age\": \"Bene_Age_Sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858f4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Number of Total Claims per Provider. The original Idea was to identify the Total Number of false Claims by a Provider. For that he subtract the number of fradulent claims from the number of total claims\n",
    "prv_total_claims_test = df_test.groupby(\"Provider\")[\"ClaimID\"].count().reset_index()\n",
    "prv_total_claims_test.columns = [\"Provider\", \"TotalClaims\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d418191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_total_claims_train = df_train.groupby(\"Provider\")[\"ClaimID\"].count().reset_index()\n",
    "prv_total_claims_train.columns = [\"Provider\", \"TotalClaims\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e06cb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define a function to compute total claims per provider for the attending physician\n",
    "def prv_total_claims_for_physicians(df):\n",
    "    \"\"\"\n",
    "    Compute total claims per provider for each physician type, and return one merged Dask DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count total claims per provider-physician type\n",
    "    att = df.groupby([\"Provider\", \"AttendingPhysician\"])[\"ClaimID\"].count().reset_index()\n",
    "    att = att.rename(columns={\"ClaimID\": \"AttendingPhysician_TotalClaims\"})\n",
    "\n",
    "    #op = df.groupby([\"Provider\", \"OperatingPhysician\"])[\"ClaimID\"].count().reset_index()\n",
    "    #op = op.rename(columns={\"ClaimID\": \"OperatingPhysician_TotalClaims\"})\n",
    "#\n",
    "    #ot = df.groupby([\"Provider\", \"OtherPhysician\"])[\"ClaimID\"].count().reset_index()\n",
    "    #ot = ot.rename(columns={\"ClaimID\": \"OtherPhysician_TotalClaims\"})\n",
    "#\n",
    "    ## Now reduce these to provider-level totals by summing claims per provider\n",
    "    att_sum = att.groupby(\"Provider\")[\"AttendingPhysician_TotalClaims\"].sum().reset_index()\n",
    "    #op_sum = op.groupby(\"Provider\")[\"OperatingPhysician_TotalClaims\"].sum().reset_index()\n",
    "    #ot_sum = ot.groupby(\"Provider\")[\"OtherPhysician_TotalClaims\"].sum().reset_index()\n",
    "\n",
    "    # Merge safely\n",
    "    #merged = att_sum.merge(op_sum, on=\"Provider\", how=\"outer\")\n",
    "    #merged = merged.merge(ot_sum, on=\"Provider\", how=\"outer\")\n",
    "\n",
    "    return att_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f5122e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_total_claims_for_physicians_test =prv_total_claims_for_physicians(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64fecfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_total_claims_for_physicians_train =prv_total_claims_for_physicians(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce976b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Prv_Physician_Count\n",
    "def prv_physician_count(df, physician_col):\n",
    "    \"\"\"\n",
    "    Count unique physicians for each provider.\n",
    "    If multiple columns are provided, all unique physician IDs across them are counted.\n",
    "    Works with Dask DataFrames.\n",
    "    \"\"\"\n",
    "    if isinstance(physician_col, list):\n",
    "        # Combine provider with all physician columns, then reshape and deduplicate\n",
    "        dfs = []\n",
    "        for col in physician_col:\n",
    "            temp = df[[\"Provider\", col]].rename(columns={col: \"Physician\"}).dropna()\n",
    "            dfs.append(temp)\n",
    "        \n",
    "        combined = dd.concat(dfs)\n",
    "        unique_counts = (\n",
    "            combined.dropna()\n",
    "            .drop_duplicates()\n",
    "            .groupby(\"Provider\")[\"Physician\"]\n",
    "            .nunique()\n",
    "            .reset_index()\n",
    "        )\n",
    "        unique_counts = unique_counts.rename(columns={\"Physician\": \"Prv_Physician_Count\"})\n",
    "\n",
    "    else:\n",
    "        unique_counts = (\n",
    "            df.groupby(\"Provider\")[physician_col]\n",
    "            .nunique()\n",
    "            .reset_index()\n",
    "            .rename(columns={physician_col: f\"{physician_col}_Count\"})\n",
    "        )\n",
    "\n",
    "    return unique_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "483409eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prv_Attphysician_count = prv_physician_count(df_test, \"AttendingPhysician\")\n",
    "#prv_OPphysician_count = prv_physician_count(df_test, \"OperatingPhysician\")\n",
    "#prv_Otphysician_count = prv_physician_count(df_test, \"OtherPhysician\")\n",
    "prv_Allphysician_count_test = prv_physician_count(df_test, [\"AttendingPhysician\", \"OperatingPhysician\", \"OtherPhysician\"])\n",
    "prv_Allphysician_count_train = prv_physician_count(df_train, [\"AttendingPhysician\", \"OperatingPhysician\", \"OtherPhysician\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "346f3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Provider_Insurance_Clam_Reimbursement_Amt\n",
    "def prv_insc_claim_reimb_amt(df):\n",
    "    \"\"\"\n",
    "    Calculate the total insurance reimbursement amount per provider.\n",
    "    \"\"\"\n",
    "    return df.groupby(\"Provider\")[\"InscClaimAmtReimbursed\"].sum().reset_index().rename(\n",
    "        columns={\"InscClaimAmtReimbursed\": \"Provider_Insurance_Claim_Reimbursement_Amt\"}\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a14d039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_insc_claim_reimb_amt_test = prv_insc_claim_reimb_amt(df_test)\n",
    "prv_insc_claim_reimb_amt_train = prv_insc_claim_reimb_amt(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f1b3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Provider_Total_Bene\n",
    "def prv_total_bene(df):\n",
    "    \"\"\"\n",
    "    Calculate the total number of unique beneficiaries per provider.\n",
    "    \"\"\"\n",
    "    return df.groupby(\"Provider\")[\"BeneID\"].nunique().reset_index().rename(\n",
    "        columns={\"BeneID\": \"Provider_Total_Patients\"}\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00a09c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_total_bene_test = prv_total_bene(df_test)\n",
    "provider_total_bene_train = prv_total_bene(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb50a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Provider_Total_Chronic_Beneficiaries\n",
    "\n",
    "def prv_total_chron_bene(df, chronic_cols):\n",
    "    \"\"\"\n",
    "    Calculates the total number of beneficiaries per provider for each chronic condition.\n",
    "\n",
    "    Parameters:\n",
    "        df (Dask or Pandas DataFrame): Input beneficiary DataFrame\n",
    "        chronic_cols (list of str): List of chronic condition columns (values should be 0 or 1)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with one row per provider and total counts of each chronic condition.\n",
    "    \"\"\"\n",
    "    # Check if all columns exist\n",
    "    missing = [col for col in chronic_cols if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"The following columns are missing: {missing}\")\n",
    "    \n",
    "    # Group and sum per provider\n",
    "    agg_df = df.groupby(\"Provider\")[chronic_cols].sum().reset_index()\n",
    "\n",
    "    # Rename columns\n",
    "    agg_df = agg_df.rename(columns={col: f\"Provider_Total_{col}_Patients\" for col in chronic_cols})\n",
    "\n",
    "    return agg_df\n",
    "chronic_cols = [\n",
    "    \"ChronicCond_Alzheimer\",\n",
    "    \"ChronicCond_Heartfailure\",\n",
    "    \"ChronicCond_KidneyDisease\",\n",
    "    \"ChronicCond_Cancer\",\n",
    "    \"ChronicCond_ObstrPulmonary\",\n",
    "    \"ChronicCond_Depression\",\n",
    "    \"ChronicCond_Diabetes\",\n",
    "    \"ChronicCond_IschemicHeart\",\n",
    "    \"ChronicCond_Osteoporasis\",\n",
    "    \"ChronicCond_rheumatoidarthritis\",\n",
    "    \"ChronicCond_stroke\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff16c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_total_chronic_bene_test = prv_total_chron_bene(df_test, chronic_cols)\n",
    "provider_total_chronic_bene_train = prv_total_chron_bene(df_train, chronic_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e33d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. count of diagnosis for every Provider\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def prv_diagnosis_count(df, diagnosis_cols):\n",
    "    \"\"\"\n",
    "    Count non-null occurrences of the ClmDiagnosisCode 1-3 per provider.\n",
    "    \n",
    "    Parameters:\n",
    "        df (Dask DataFrame): Input DataFrame containing diagnosis codes\n",
    "        diagnosis_cols (list of str): List of diagnosis code columns\n",
    "    \n",
    "    Returns:\n",
    "        Dask DataFrame with counts of each diagnosis column per provider\n",
    "    \"\"\"\n",
    "    # Start with the first column's counts\n",
    "    result = df.groupby(\"Provider\")[diagnosis_cols[0]].count().reset_index().rename(\n",
    "        columns={diagnosis_cols[0]: f\"{diagnosis_cols[0]}_Count\"}\n",
    "    )\n",
    "    \n",
    "    # Iterate through remaining diagnosis columns and join counts\n",
    "    for col in diagnosis_cols[1:]:\n",
    "        temp = df.groupby(\"Provider\")[col].count().reset_index().rename(\n",
    "            columns={col: f\"{col}_Count\"}\n",
    "        )\n",
    "        result = result.merge(temp, on=\"Provider\", how=\"outer\")\n",
    "\n",
    "    return result\n",
    "diagnosis_cols = [\n",
    "    \"ClmAdmitDiagnosisCode\",\n",
    "    \"ClmDiagnosisCode_1\",\n",
    "    \"ClmDiagnosisCode_2\",\n",
    "    \"ClmDiagnosisCode_3\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28f01322",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_diagnosis_count_test = prv_diagnosis_count(df_test, diagnosis_cols)\n",
    "prv_diagnosis_count_train = prv_diagnosis_count(df_train, diagnosis_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c88d126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Most frequent Claimcodes for every Provider\n",
    "from functools import reduce\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def prv_most_frequent_claim_codes(df, claim_code_cols):\n",
    "    \"\"\"\n",
    "    Find the most frequent claim code for each provider across multiple columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (Dask DataFrame): Input DataFrame containing claim codes\n",
    "        claim_code_cols (list of str): List of claim code column names\n",
    "    \n",
    "    Returns:\n",
    "        Dask DataFrame: Each row contains Provider and the most frequent code per claim column\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for col in claim_code_cols:\n",
    "        # Count frequencies per Provider per code\n",
    "        code_counts = (\n",
    "            df.groupby([\"Provider\", col])\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"Count\"})\n",
    "        )\n",
    "\n",
    "        # Sort within each partition, then drop duplicates to get most frequent\n",
    "        most_frequent = (\n",
    "            code_counts.map_partitions(lambda pdf: pdf.sort_values(\"Count\", ascending=False))\n",
    "            .drop_duplicates(subset=\"Provider\")\n",
    "            .rename(columns={col: f\"{col}_Most_Frequent\"})\n",
    "            .drop(columns=[\"Count\"])\n",
    "        )\n",
    "\n",
    "        results.append(most_frequent)\n",
    "\n",
    "    # Merge all the most frequent codes per column\n",
    "    final_result = reduce(lambda left, right: left.merge(right, on=\"Provider\", how=\"outer\"), results)\n",
    "\n",
    "    return final_result\n",
    "\n",
    "claim_code_cols = [\n",
    "    \"ClmAdmitDiagnosisCode\",\n",
    "    \"ClmDiagnosisCode_1\",\n",
    "    \"ClmDiagnosisCode_2\",\n",
    "    \"ClmDiagnosisCode_3\",\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27b3f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_most_frequent_claim_codes_test = prv_most_frequent_claim_codes(df_test, claim_code_cols)\n",
    "prv_most_frequent_claim_codes_train = prv_most_frequent_claim_codes(df_train, claim_code_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b565d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def prv_most_frequent_physicians(df, physician_cols):\n",
    "    \"\"\"\n",
    "    Find the most frequent physician for each provider across multiple physician columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (Dask DataFrame): Input DataFrame containing provider and physician columns\n",
    "        physician_cols (list of str): List of physician column names\n",
    "    \n",
    "    Returns:\n",
    "        Dask DataFrame: Each row contains Provider and the most frequent physician per column\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for col in physician_cols:\n",
    "        # Count frequencies per Provider per Physician\n",
    "        physician_counts = (\n",
    "            df.groupby([\"Provider\", col])\n",
    "            .size()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"Count\"})\n",
    "        )\n",
    "\n",
    "        # Sort by frequency, then get most frequent physician per provider\n",
    "        most_frequent = (\n",
    "            physician_counts.map_partitions(lambda pdf: pdf.sort_values(\"Count\", ascending=False))\n",
    "            .drop_duplicates(subset=\"Provider\")\n",
    "            .rename(columns={col: f\"{col}_Most_Frequent\"})\n",
    "            .drop(columns=[\"Count\"])\n",
    "        )\n",
    "\n",
    "        results.append(most_frequent)\n",
    "\n",
    "    # Merge all the most frequent physician columns on Provider\n",
    "    final_df = reduce(lambda left, right: left.merge(right, on=\"Provider\", how=\"outer\"), results)\n",
    "\n",
    "    return final_df\n",
    "physician_cols = [\n",
    "    \"AttendingPhysician\",\n",
    "    \"OperatingPhysician\",\n",
    "    \"OtherPhysician\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f18a90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_most_frequent_physicians_test = prv_most_frequent_physicians(df_test, physician_cols)\n",
    "prv_most_frequent_physicians_train = prv_most_frequent_physicians(df_train, physician_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8be32c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. bene deductible and claimcost amount\n",
    "def bene_calculate_amount(df):\n",
    "    \"\"\"\n",
    "    Return a Dask DataFrame with BeneID, AllocatedAmount (as-is), and summed Deductible & Reimbursed amounts.\n",
    "\n",
    "    Parameters:\n",
    "        df (Dask DataFrame): Input with reimbursement and deductible fields\n",
    "\n",
    "    Returns:\n",
    "        Dask DataFrame with columns: BeneID, AllocatedAmount, DeductibleAmtPaid (sum), InscClaimAmtReimbursed (sum)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Calculate AllocatedAmount (not to be summed)\n",
    "    df[\"AllocatedAmount\"] = df[\"IPAnnualReimbursementAmt\"] + df[\"OPAnnualReimbursementAmt\"]\n",
    "\n",
    "    # Get first AllocatedAmount per BeneID (assuming same for all rows of that BeneID)\n",
    "    allocated = df[[\"BeneID\", \"AllocatedAmount\"]].drop_duplicates(subset=\"BeneID\")\n",
    "\n",
    "    # Sum the other columns per BeneID\n",
    "    summed = df.groupby(\"BeneID\")[[\"DeductibleAmtPaid\", \"InscClaimAmtReimbursed\"]].sum().reset_index()\n",
    "   \n",
    "\n",
    "    # Merge\n",
    "    result = allocated.merge(summed, on=\"BeneID\", how=\"left\")\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36ca7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "bene_calculate_amount_test = bene_calculate_amount(df_test)\n",
    "bene_calculate_amount_train = bene_calculate_amount(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d610747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>Avg_allocated_Amount_Per_Provider</th>\n",
       "      <th>Avg_Deductible_Amt_Paid_Per_Provider</th>\n",
       "      <th>Avg_InscClaimAmtReimbursed_Per_Provider</th>\n",
       "      <th>perc_allocated_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51002</td>\n",
       "      <td>7526.000000</td>\n",
       "      <td>72.409756</td>\n",
       "      <td>1322.585366</td>\n",
       "      <td>0.167728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51006</td>\n",
       "      <td>6169.215686</td>\n",
       "      <td>75.156863</td>\n",
       "      <td>1617.254902</td>\n",
       "      <td>0.253049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51009</td>\n",
       "      <td>5445.128205</td>\n",
       "      <td>121.384615</td>\n",
       "      <td>1767.435897</td>\n",
       "      <td>0.309191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51010</td>\n",
       "      <td>7044.210526</td>\n",
       "      <td>449.684211</td>\n",
       "      <td>4747.105263</td>\n",
       "      <td>0.651665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51018</td>\n",
       "      <td>7551.894737</td>\n",
       "      <td>53.968421</td>\n",
       "      <td>1332.000000</td>\n",
       "      <td>0.170451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  Avg_allocated_Amount_Per_Provider  \\\n",
       "0  PRV51002                        7526.000000   \n",
       "1  PRV51006                        6169.215686   \n",
       "2  PRV51009                        5445.128205   \n",
       "3  PRV51010                        7044.210526   \n",
       "4  PRV51018                        7551.894737   \n",
       "\n",
       "   Avg_Deductible_Amt_Paid_Per_Provider  \\\n",
       "0                             72.409756   \n",
       "1                             75.156863   \n",
       "2                            121.384615   \n",
       "3                            449.684211   \n",
       "4                             53.968421   \n",
       "\n",
       "   Avg_InscClaimAmtReimbursed_Per_Provider  perc_allocated_used  \n",
       "0                              1322.585366             0.167728  \n",
       "1                              1617.254902             0.253049  \n",
       "2                              1767.435897             0.309191  \n",
       "3                              4747.105263             0.651665  \n",
       "4                              1332.000000             0.170451  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bene_amount_avg_prv_test= dd.merge(\n",
    "    df_test[[\"BeneID\", \"Provider\"]],\n",
    "    bene_calculate_amount_test,\n",
    "    on=\"BeneID\",\n",
    "    how=\"left\"\n",
    ").groupby(\"Provider\")[\"AllocatedAmount\", 'DeductibleAmtPaid', \"InscClaimAmtReimbursed\"].mean().reset_index()\n",
    "bene_amount_avg_prv_test = bene_amount_avg_prv_test.rename(\n",
    "    columns={\"AllocatedAmount\": \"Avg_allocated_Amount_Per_Provider\", 'DeductibleAmtPaid': \"Avg_Deductible_Amt_Paid_Per_Provider\", \"InscClaimAmtReimbursed\": \"Avg_InscClaimAmtReimbursed_Per_Provider\" }\n",
    ")\n",
    "bene_amount_avg_prv_test['perc_allocated_used'] = (bene_amount_avg_prv_test[\"Avg_InscClaimAmtReimbursed_Per_Provider\"] - bene_amount_avg_prv_test[\"Avg_Deductible_Amt_Paid_Per_Provider\"]) /(bene_amount_avg_prv_test[\"Avg_allocated_Amount_Per_Provider\"] - bene_amount_avg_prv_test[\"Avg_Deductible_Amt_Paid_Per_Provider\"])\n",
    "bene_amount_avg_prv_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92f66eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_perc=bene_amount_avg_prv_test['perc_allocated_used'].max().compute()\n",
    "max_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc045e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_perc=bene_amount_avg_prv_test['perc_allocated_used'].min().compute()\n",
    "min_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c2c9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_date = df_train.copy()\n",
    "max_date = dd.to_datetime(df_train_date['ClaimStartDt'], errors='coerce').max().compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b2da012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2009-12-31 00:00:00')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0162c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = dd.to_datetime(df_train_date['ClaimStartDt'], errors='coerce').min().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9f6be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2008-11-27 00:00:00')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "054b0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a new column to indicate the quarter of the year for every claim\n",
    "def add_quarter_column(df):\n",
    "    \"\"\"\n",
    "    Add a 'Quarter' column based on ClaimStartDt.\n",
    "    - 2009 quarters are numbered 1–4\n",
    "    - 2008 quarters are numbered 101–104\n",
    "    \"\"\"\n",
    "    # Convert to datetime safely\n",
    "    df['ClaimStartDt'] = dd.to_datetime(df['ClaimStartDt'], errors='coerce')\n",
    "\n",
    "    # Extract year and quarter\n",
    "    df['Year'] = df['ClaimStartDt'].dt.year\n",
    "    df['Quarter'] = df['ClaimStartDt'].dt.quarter\n",
    "\n",
    "    # Apply conditional logic: use different quarter labels for 2008\n",
    "    df['Quarter'] = df.apply(\n",
    "        lambda row: row.Quarter if row.Year == 2009 else (0 if row.Year == 2008 else None),\n",
    "        axis=1,\n",
    "        meta=('Quarter', 'float64')  # must specify meta for Dask apply\n",
    "    )\n",
    "\n",
    "    # Drop temporary year column if not needed\n",
    "    df = df.drop('Year', axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f1be14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeneID</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>ClaimStartDt</th>\n",
       "      <th>ClaimEndDt</th>\n",
       "      <th>Provider</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>AttendingPhysician</th>\n",
       "      <th>OperatingPhysician</th>\n",
       "      <th>OtherPhysician</th>\n",
       "      <th>AdmissionDt</th>\n",
       "      <th>ClmAdmitDiagnosisCode</th>\n",
       "      <th>DeductibleAmtPaid</th>\n",
       "      <th>DischargeDt</th>\n",
       "      <th>DiagnosisGroupCode</th>\n",
       "      <th>ClmDiagnosisCode_1</th>\n",
       "      <th>ClmDiagnosisCode_2</th>\n",
       "      <th>ClmDiagnosisCode_3</th>\n",
       "      <th>ClmDiagnosisCode_4</th>\n",
       "      <th>ClmDiagnosisCode_5</th>\n",
       "      <th>ClmDiagnosisCode_6</th>\n",
       "      <th>ClmDiagnosisCode_7</th>\n",
       "      <th>ClmDiagnosisCode_8</th>\n",
       "      <th>ClmDiagnosisCode_9</th>\n",
       "      <th>ClmDiagnosisCode_10</th>\n",
       "      <th>ClmProcedureCode_1</th>\n",
       "      <th>ClmProcedureCode_2</th>\n",
       "      <th>ClmProcedureCode_3</th>\n",
       "      <th>ClmProcedureCode_4</th>\n",
       "      <th>ClmProcedureCode_5</th>\n",
       "      <th>ClmProcedureCode_6</th>\n",
       "      <th>ClaimDuration</th>\n",
       "      <th>HospitalDuration</th>\n",
       "      <th>DOB</th>\n",
       "      <th>DOD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>RenalDiseaseIndicator</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>ChronicCond_Alzheimer</th>\n",
       "      <th>ChronicCond_Heartfailure</th>\n",
       "      <th>ChronicCond_KidneyDisease</th>\n",
       "      <th>ChronicCond_Cancer</th>\n",
       "      <th>ChronicCond_ObstrPulmonary</th>\n",
       "      <th>ChronicCond_Depression</th>\n",
       "      <th>ChronicCond_Diabetes</th>\n",
       "      <th>ChronicCond_IschemicHeart</th>\n",
       "      <th>ChronicCond_Osteoporasis</th>\n",
       "      <th>ChronicCond_rheumatoidarthritis</th>\n",
       "      <th>ChronicCond_stroke</th>\n",
       "      <th>IPAnnualReimbursementAmt</th>\n",
       "      <th>IPAnnualDeductibleAmt</th>\n",
       "      <th>OPAnnualReimbursementAmt</th>\n",
       "      <th>OPAnnualDeductibleAmt</th>\n",
       "      <th>Bene_Age</th>\n",
       "      <th>Bene_Alive</th>\n",
       "      <th>AllocatedAmount</th>\n",
       "      <th>Quarter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<div>Dask Name: drop_by_shallow_copy, 43 expressions</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               BeneID ClaimID    ClaimStartDt ClaimEndDt Provider InscClaimAmtReimbursed AttendingPhysician OperatingPhysician OtherPhysician AdmissionDt ClmAdmitDiagnosisCode DeductibleAmtPaid DischargeDt DiagnosisGroupCode ClmDiagnosisCode_1 ClmDiagnosisCode_2 ClmDiagnosisCode_3 ClmDiagnosisCode_4 ClmDiagnosisCode_5 ClmDiagnosisCode_6 ClmDiagnosisCode_7 ClmDiagnosisCode_8 ClmDiagnosisCode_9 ClmDiagnosisCode_10 ClmProcedureCode_1 ClmProcedureCode_2 ClmProcedureCode_3 ClmProcedureCode_4 ClmProcedureCode_5 ClmProcedureCode_6 ClaimDuration HospitalDuration     DOB     DOD Gender   Race RenalDiseaseIndicator  State County ChronicCond_Alzheimer ChronicCond_Heartfailure ChronicCond_KidneyDisease ChronicCond_Cancer ChronicCond_ObstrPulmonary ChronicCond_Depression ChronicCond_Diabetes ChronicCond_IschemicHeart ChronicCond_Osteoporasis ChronicCond_rheumatoidarthritis ChronicCond_stroke IPAnnualReimbursementAmt IPAnnualDeductibleAmt OPAnnualReimbursementAmt OPAnnualDeductibleAmt Bene_Age Bene_Alive AllocatedAmount  Quarter\n",
       "npartitions=1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "               string  string  datetime64[ns]     string   string                float64             string             string         string      string                string           float64      string             string             string             string             string             string             string             string             string             string             string              string            float64            float64            float64            float64            float64            float64         int64          float64  string  string  int64  int64                 int64  int64  int64                 int64                    int64                     int64              int64                      int64                  int64                int64                     int64                    int64                           int64              int64                  float64               float64                  float64               float64    int64      int64         float64  float64\n",
       "                  ...     ...             ...        ...      ...                    ...                ...                ...            ...         ...                   ...               ...         ...                ...                ...                ...                ...                ...                ...                ...                ...                ...                ...                 ...                ...                ...                ...                ...                ...                ...           ...              ...     ...     ...    ...    ...                   ...    ...    ...                   ...                      ...                       ...                ...                        ...                    ...                  ...                       ...                      ...                             ...                ...                      ...                   ...                      ...                   ...      ...        ...             ...      ...\n",
       "Dask Name: drop_by_shallow_copy, 43 expressions\n",
       "Expr=Drop(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=Assign(frame=ReadCSV(69e46bf)))))))))))), columns='Year')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_quarter_column(df_train)\n",
    "add_quarter_column(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fad933d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max=df_train['Quarter'].min().compute() \n",
    "max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef1c014",
   "metadata": {},
   "source": [
    "Merging Stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e00a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "249275d0",
   "metadata": {},
   "source": [
    "Saving the Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0743f96",
   "metadata": {},
   "source": [
    "After Merging calcution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6993d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Real Average Claims per Provider we have to run this after merging the dataframes\n",
    "#df_train['real_avg_claims_per_provider'] = df_train['TotalClaims'] - df_train['TotalClaims'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Average of Claimcost for every Provider\n",
    "df_train['real_avg_claim_cost_per_provider'] = df_train['Provider_Insurance_Claim_Reimbursement_Amt'] - df_train['Provider_Insurance_Claim_Reimbursement_Amt'].mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4730cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Median of the Claimscost for every Provider\n",
    "df_train['real_median_claim_cost_per_provider'] = df_train['Provider_Insurance_Claim_Reimbursement_Amt'] - df_train['Provider_Insurance_Claim_Reimbursement_Amt'].median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
